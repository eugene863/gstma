{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1b3693-9db0-4f70-a1d5-816443ca9ba4",
   "metadata": {},
   "source": [
    "Пример Spark Legacy Streaming\n",
    "=============================\n",
    "\n",
    "Пример с использованием Spark Streaming. Это устаревшая технология."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6179e-ecca-4395-b8df-8097e5aed334",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3114be-0ef1-4896-a9e7-1c04ebc32250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.0`\n",
    "import $ivy.`org.apache.spark::spark-streaming:2.4.0`\n",
    "import $ivy.`org.apache.spark::spark-streaming-kafka-0-10:2.4.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f15076-8db7-4e72-88ba-a47b0bf1712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.kafka.clients.consumer.ConsumerRecord\n",
    "import org.apache.kafka.common.serialization.StringDeserializer\n",
    "import org.apache.spark.streaming.kafka010._\n",
    "import org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent\n",
    "import org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe\n",
    "\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.streaming._\n",
    "import org.apache.spark.streaming.StreamingContext._ // not necessary since Spark 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6a69c-2b70-4cd2-a3b2-0b0f0fc9c001",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b528ca8-a8e8-4864-93bc-d326e52006b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a local StreamingContext with two working thread and batch interval of 1 second.\n",
    "// The master requires 2 cores to prevent a starvation scenario.\n",
    "\n",
    "val conf = new SparkConf()\n",
    "  .setMaster(\"local[*]\")\n",
    "  .setAppName(\"NetworkWordCount\")\n",
    "val ssc = new StreamingContext(conf, Seconds(1))\n",
    "\n",
    "val kafkaParams = Map[String, Object](\n",
    "  // Использование Docker DNS позволяет обращаться к контейнерам по именам внутри одной\n",
    "  // Docker-сети. Поэтому в `bootstrap.servers` прописано имя контейнера:\n",
    "  \"bootstrap.servers\" -> \"kafka:9092\",\n",
    "  \"key.deserializer\" -> classOf[StringDeserializer],\n",
    "  \"value.deserializer\" -> classOf[StringDeserializer],\n",
    "  \"group.id\" -> \"use_a_separate_group_id_for_each_stream\",\n",
    "  \"auto.offset.reset\" -> \"latest\",\n",
    "  \"enable.auto.commit\" -> (false: java.lang.Boolean)\n",
    ")\n",
    "\n",
    "val topics = Array(\"rawdata.range\")\n",
    "val stream = KafkaUtils.createDirectStream[String, String](\n",
    "  ssc,\n",
    "  PreferConsistent,\n",
    "  Subscribe[String, String](topics, kafkaParams)\n",
    ")\n",
    "\n",
    "val query = stream.map(record => (record.key, record.value))\n",
    "//  .writeStream\n",
    "//  .outputMode(\"complete\")\n",
    "//  .format(\"console\")\n",
    "//  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce60656-7bad-4573-af32-2b0ebc0f6d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb32ac-4029-4f06-8b48-852285e0eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()             // Start the computation\n",
    "ssc.awaitTermination()  // Wait for the computation to terminate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala2.12"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
